---
layout: post
title: r_jit
date: 2023-02-04 18:25 +0800
---

# Improvements of the RIR bytecode toolchain

Jan Ječmen wrote a master's thesis about the evaluation process in R programming language. R evaluation starts with the core R, which takes input and creates a tree with nodes as SEXPS (abstract syntax tree). The tree is then walked recursively, and actions are performed based on the type of node encountered.

There are three types of functions in R: special functions, built-in functions, and closures. Built-in functions are the simplest to evaluate, as they evaluate all their arguments. Closures, or user-defined functions, create an environment of promises. Special functions, used for control flow, take their arguments as abstract syntax trees and evaluate them as needed.

R has a bytecode compiler that walks the abstract syntax tree and produces bytecode objects. These objects consist of two components: an integer vector that represents opcodes, instruction versions, and operands, and a constant pool that stores important objects and constants used during the compile process.

The bytecode objects are executed by the virtual machine (VM) using a stack-oriented architecture. The VM receives a bytecode object and an environment, verifies the version, and dispatches to the code that implements the instruction.

Compilation in R involves several steps. Constants are inserted into the constant pool and loaded as instructions. Variable references are inserted into the constant pool and loaded as GETVAR instructions. Function calls are compiled by first compiling the function, then compiling the arguments, and finally generating a call instruction. The compiler tracks local and global bindings and assumes the meaning of certain functions.

R is challenging to optimize because it is an interpreted language, which incurs interpreter overhead, requires garbage collection, and has values that are boxed, leading to multiple levels of indirection.

Jan Ječmen introduces RIR, a drop-in replacement for the GNU R bytecode compiler, which is designed to be predictable and self-contained. At present, RIR is slower than GNU R, but the author made three changes to improve its performance.

Added new instructions and operators that were not in the original RIR, including optimized compare operators.
Changed the RIR compiler loop context handling to improve performance in cases with lazy evaluation.
Refactored the interpreter code, including replacing inline with macro and threaded code dispatching, which resulted in the biggest speedup.

1. add instruction 
 
And new operator that not exsiting in original rir(like compare operators other than'<'). As for compare operators, if we have suitable operands type, we can unwrap them and take a fast path.

The complicated part is subset assignment, the principal is look the LHS value and save it to tmp variable, then calle function pass the tmp and RHS and assign it to x.

for superassignment, we can depart it into two instructions: find and load symbol and push data to symbol back.

2. change the rir compiler loop context handling. 

Lazy evaluation in R may lead to a non-local jumps(i.e. across multiple stack frames).  If a loop contains any break or next statements that are wrapped in a promise, the loop context is needed, except for the case they are wrapped in another loop.

Author design mechanism to skip those safe case, and add a few BC code cleanup(optimization)

3. refactored the interperter code. 

gains biggest speedup, including replace inline with macro and threaded code dispatching


# R Melts Brains

In this thesis, author present their work on PIR, an intermediate represatation for R. They describe two dataflow analyses to elide environment creation and inline function.

Here are few example serves as motivation of introducing PIR.

## example 1
`function() {answer <- 42; answer}` can translate into 

```
e0 = MkEnv ( : G) # G is the global environment
%1 = LdConst [1] 42 # 42 is loaded as a vector of length 1
StVar (answer, %1, e0) # update e0 with a bingding for symbol "answer"
%3 = LdVar (answer, e0) # loads variables named "answer from e0  
%4 = Force (%3) e0 # evaluate a promise
Return (%4)
```

After translation, we can analyse the code can find the answer symbol originates from StVar, thus could be substituded with %1. A Phi instruction is needed if there exists muliple dominating(?) store. Once the load is resolved, the environment will be discarded. 

## example 2

A promise can be elided with the following three steps: first inline the callee function, next identify where the promise is evaluated, then inline the promise at that location. 

```
f <- function(b) b
f(x)
```

the call to function can be translated into the following PIR:

```
%1 = MkClosure (f, G) # create a closure 
%2 = MkArg (pr0, G) #create a promise from pr0 in G.
%3 = Call %1 (%2) G # call function with promise 
pr0 # parameter as a function
%4 = LdVar (x, G) 
%5 = Force (%4) G # load and evaluate x
Return (%5) 
```

the function defination can be translated into the following PIR:

```
f
%6 = LdArg (0)
e7 = MkEnv (b = %6 : G)
%8 = Force (%6) e7
Return (%8)
```

The callees initialize environments with arguments , loads arguments by position and binds it to variable.

As the step we mentioned above, we first inline the callee function. The the envirment specify in LdVar prevent mix variables definition. We get 

```
%2 = MkArg (pr0, G) #create a promise from pr0 in G.
e7 = MkEnv (b = %2 : G)
%8 = Force (%2) e7
Return (%8)
```

The next step is indentify where the promise is evaluted, we find a Force instruction dominates all other uses of %2, so that's where evaluation happens. Finally, we inline pr0 to replace %8.

```
# %2 = MkArg (pr0, G) (dead code)
# e7 = MkEnv (b = %2 : G) (dead code)
%4 = LdVar (x, G) 
%5 = Force (%4) G # load and evaluate x
Return (%5)
```

## Syntax and Semantics

Each function in PIR is versioned with different assumptions (e.g. ) upon what  may hold for execution of a function.  

##  Scope Resolution

Scope resolution is a compiler optimization pass that helps to reduce unnecessary environment use in the compiler. It draws inspriation from mem2reg pass.

- how to implement it

definition: 


an (abstract) state: is a matrix of sets, where each set represents a location of possible change source.

A location can be either a program pointer or an undefined variable.

The transition function in scope resolution takes in three inputs: a program point, a statement, and a state. It then returns a new state based on the statement.

$$s' = transition_function(l,st,s)$$

There are three cases for the transition function:

- Creating a new environment $ei$:
$$ei=MkEnv(x_1=a_1,\dots,x_j=a_j:e_k)$$
The return vector will set $l$ to $x_1\dots x_j$ and set other variables to undefined.

- Storing a variable:
$$StVar(x_i,%j,e_k)$$
This will simply overwrite $s_{i,j}$.

- Reflective manipulation:
$$call\ a_0 (a_1,\dots,a_n) e_k$$
This sets all variables to the set of all locations.

When a load instruction is reached:
$$%i=LdVar(x_j,e_k)$$
with a state $s$, if $s_{k,j} = {l}$ then we can replace $%i$ by the register $l$ points to. If $s_{k,j}$ is a set with multiple elements, we construct a phi node. If the location is whole set, no optimization is applied.

## Improving Precision

we can do more to make scope resolution useful in practice. 

- Contextual Assumptions

If are arguments are value, we could ignore the dangers of promise evaluation. 

- Stub Environment 

A stub environment is a compact representation of an environment that can be transformed into a full environment if modified. "Materialized" means the transformation of a stub environment into a full environment.

## Delaying Environments

The deoptimization mechanism in R transfers control back to the unoptimized version of a function. This is done by checking an assumption, represented by a boolean instruction, and if it holds, continuing to a different block, otherwise entering the deoptimization branch. The deoptimization branch contains a \Deopt instruction that has all the metadata needed to transfer control back to the baseline version of the function and requires the environment of the function to be present. To avoid creating an environment at runtime whenever a compiled function performs any kind of speculative optimization, creation of environments should be delayed. A technique called partial escape analysis is used to delay an allocation to only those branches where the object escapes. In PIR, the goal is to materialize an up-to-date environment in each deoptimization branch, allowing to elide the environment in the main path. This requires replaying stores between the original environment creation and the \Deopt instruction. A sufficient condition for this is that at the \Deopt instruction, none of the variables in the abstract state is $\top$.


# Promise Inlining

Promise inlining is a process in which the body of a promise is executed and its result is replaced with the actual value at the location of its dominant force instruction. The analysis required for this process involves a simple dataflow analysis to track the state of the promises. The states of the promises can be $\bot$, $l$, $\triangledown$, or $\top$ which represent not forced, forced at program point $l$, leaked, and forced and leaked respectively. The transition function takes a statement and the abstract state of the promises and returns a new state. The merge function combines two states and resolves disagreements by setting the result to $\top$. The code transformation pass uses the analysis to inline the promise at its dominant force location, replace all uses with the result of the inlinee, and remove both the creation and force instructions. The process of promise inlining can only be performed on promises within the same function and their bodies must be known.

A "leaked" state in the context of Promise Inlining refers to a promise (created by a \MkArg instruction) whose value has been passed to an environment (created by a \MkEnv instruction). When a promise is leaked, it is not guaranteed to be forced (i.e., evaluated), and therefore its state is set to "leaked" to indicate that it may be evaluated in the future.